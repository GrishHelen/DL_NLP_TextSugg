# Text Suggestor. Описание системы

### Пример: 

<img width="1467" height="838" alt="image" src="https://github.com/user-attachments/assets/5ea3b045-c43d-4b28-bc09-a48df3ee012b" />

### Как это видит пользователь?

Мой сервис - локальный сайт с простейшим функционалом. Пользователь вводит текст, а модель рекомендует ему наиболее вероятные продолжения. 
Возможные продолжения появляются кнопками под окном ввода текста, для переключения между которыми можно воспользоваться стрелками на клавиатуре. 
Чтобы выбрать продолжение и подставить его в окно ввода, просто кликните по выбранной кнопке. 
_Для удобства пользования я старалась сделать также выбор по нажатию клавиши `Enter`, но это мне не удалось: эта клавиша редактирует текст_

### Как это работает? 

Когда пользователь вводит новый символ в поле ввода, срабатывает триггер `on_change`, и введенный текст сохраняется. 

При нажатии любой клавиши (т.е. в том числе и при изменении текста) запускается процесс предсказания наиболее вероятных продолжений для него. 
Для продолжения текста используется класс TextSuggestion, инстанс которого предсохранен в основной части ДЗ, а в этой части используется уже готовый инстанс, подгружаемый из файла.
Хочется подробнее поговорить о его параметрах, которые я зафиксировала:
- `max_complete_words=3` - число вариантов дополнения последнего слова
- `n_texts=5` - максимальное количество продолжений, которое вернет модель 
- `n_words=3` - число слов, которые дописывает n-граммная модель, то есть каждое продолжение будет состоять из 3 слов (+1 - последнее введенное слово, с вариантами дополнения)
- `n_best_words=3`. Для каждого из дописываемых слов n-граммная модель возьмет до 3 самых популярных вариантов

Также стоит упомянуть, что я использую 3-граммную модель, то есть использую тройки слов как контекст. 
Этого достаточно, чтобы окно контекста содержало смысл. 
Но если делать окно больше, то контекст слишком _уникальный_, и меньше вероятность, что в предобработанном датасете найдется подходящая n-грамма.

Еще важный момент: для ускорения процесса подбора самых вероятных продолжений введенного текста я включила в словарь только слова, 
которые встречались в исходном датасете больше `corpus_border=5` раз.

### Что еще можно было бы сделать?

1. Мне не нравится, что долго работает подбор самых вероятных продолжений. У меня есть две идеи, которые можно было бы попробовать:
   - Оптимизации словаря слов: уменьшить число используемых слов. Но тогда мы сильно потеряли бы в возможностях продолжения текстов
   - Использовать Beam Search при поиске самых вероятных последовательностей для продолжения 
(т.е. поддерживать только M самых вероятных последовательностей на каждом этапе, на каждом уровне графа)
2. Интерфейс. Сейчас не понятно, что первое слово на кнопках с рекомендациями - это дополнение последнего введенного. Можно было бы выделять первое слово цветом, например.
   А еще сейчас я выдаю пользователю продолжения строго зафиксированной мною длины, а можно выдавать 'не длиннее, чем ...'



